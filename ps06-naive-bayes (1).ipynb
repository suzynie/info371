{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8e6260-91f6-4492-a387-4f2f20786f0f",
   "metadata": {
    "id": "5b8e6260-91f6-4492-a387-4f2f20786f0f"
   },
   "source": [
    "wa# INFO 371 Problem Set #6: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac7de3b-e73d-4bfc-abf7-87542e484762",
   "metadata": {
    "id": "aac7de3b-e73d-4bfc-abf7-87542e484762"
   },
   "source": [
    "Chesie Yu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71682a91-3f0b-4ebf-b525-628cb4281faf",
   "metadata": {
    "id": "71682a91-3f0b-4ebf-b525-628cb4281faf"
   },
   "source": [
    "02/14/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab16016-56b3-41eb-8ae7-111d68764d8c",
   "metadata": {
    "id": "7ab16016-56b3-41eb-8ae7-111d68764d8c"
   },
   "source": [
    "<style type=\"text/css\" >\n",
    "  body{\n",
    "    font-family: \"Serif\";\n",
    "    font-size: 12pt\n",
    "  }\n",
    "  em {\n",
    "\tcolor: #4E7F9E;\n",
    "  }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc0d5364-ab0b-47d2-a108-f4dfec30ea02",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1645257969517,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "fc0d5364-ab0b-47d2-a108-f4dfec30ea02"
   },
   "outputs": [],
   "source": [
    "# Import the packages (as usual, the exercises...)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385bd8c6-5e2c-425f-a4a9-991ab21368b6",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bd4b2c-db8b-4f47-9ca4-ab37c673e1d8",
   "metadata": {
    "id": "34bd4b2c-db8b-4f47-9ca4-ab37c673e1d8"
   },
   "source": [
    "# 1 Load Data and Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931a2136-be21-4a96-b8de-d6561d9d9dc2",
   "metadata": {
    "id": "931a2136-be21-4a96-b8de-d6561d9d9dc2"
   },
   "source": [
    "1\\. (2pt) Load and clean data. Feel free to copy-paste from your PS05 solution.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ef0cdb5-5e4c-4dcf-9ee6-4fd470a0ef57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 778,
     "status": "ok",
     "timestamp": 1645258058077,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "2ef0cdb5-5e4c-4dcf-9ee6-4fd470a0ef57",
    "outputId": "0f3e1e97-2275-48a4-a140-21019bf6755b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Subject: re : 2 . 882 s - &gt; np np  &gt; date : su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>Subject: s - &gt; np + np  the discussion of s - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>Subject: 2 . 882 s - &gt; np np  . . . for me it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>Subject: gent conference  \" for the listserv \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>Subject: query : causatives in korean  could a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    spam                                            message\n",
       "0  False  Subject: re : 2 . 882 s - > np np  > date : su...\n",
       "1  False  Subject: s - > np + np  the discussion of s - ...\n",
       "2  False  Subject: 2 . 882 s - > np np  . . . for me it ...\n",
       "3  False  Subject: gent conference  \" for the listserv \"...\n",
       "4  False  Subject: query : causatives in korean  could a..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "email = pd.read_csv(\"lingspam-emails.csv.bz2\", \n",
    "                    usecols = [\"spam\", \"message\"], sep = \"\\t\")\n",
    "email.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8bba0bb-1eff-4211-a97c-69e3b686fb68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1645257971219,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "d8bba0bb-1eff-4211-a97c-69e3b686fb68",
    "outputId": "0c4b765d-848e-4810-b0a5-2e26a34b1907"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2893, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape\n",
    "email.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "686948b1-3ab4-4484-856f-f3c874e6c333",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1645257971219,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "686948b1-3ab4-4484-856f-f3c874e6c333",
    "outputId": "439df6f5-61b3-45ff-94f8-19ad5b430827"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam       0\n",
       "message    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missings!\n",
    "email.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c47187-ce8b-4df8-b448-82c5a44c9fe6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1645257971441,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "64c47187-ce8b-4df8-b448-82c5a44c9fe6",
    "outputId": "7101ccde-8ea3-401f-853f-2fb836ce6266"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any empty strings\n",
    "np.sum(email.message == \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1219e6c-70ee-4023-82aa-9942fb43ddf2",
   "metadata": {
    "id": "f1219e6c-70ee-4023-82aa-9942fb43ddf2"
   },
   "source": [
    "_The data looks nice and clean (but with a lot of spams!)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55330106-aaa8-458f-bf26-311121879a70",
   "metadata": {
    "id": "55330106-aaa8-458f-bf26-311121879a70"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c4d376-44c9-4033-998d-3c380b0add1d",
   "metadata": {
    "id": "90c4d376-44c9-4033-998d-3c380b0add1d"
   },
   "source": [
    "2\\. (2pt) Vectorize emails so you have a DTM (I’ll refer to this as the design matrix $X$) and the spam/non-spam indicator $y$. If you don’t know how to do it, you can just use the code below:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d1d079-34e9-4f05-ab18-2fb9f7bc7832",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1645257971442,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "57d1d079-34e9-4f05-ab18-2fb9f7bc7832"
   },
   "outputs": [],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24a2224b-ce80-421f-bdcf-636c04131466",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 2087,
     "status": "ok",
     "timestamp": 1645257973526,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "24a2224b-ce80-421f-bdcf-636c04131466",
    "outputId": "96d66e22-993e-4ddb-95d1-36af68c8c31d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>00001</th>\n",
       "      <th>00003000140</th>\n",
       "      <th>00003003958</th>\n",
       "      <th>00007</th>\n",
       "      <th>0001</th>\n",
       "      <th>00010</th>\n",
       "      <th>00014</th>\n",
       "      <th>...</th>\n",
       "      <th>zwischen</th>\n",
       "      <th>zwitserlood</th>\n",
       "      <th>zxgah7qabjh</th>\n",
       "      <th>zybatov</th>\n",
       "      <th>zybatow</th>\n",
       "      <th>zygmunt</th>\n",
       "      <th>zyokyoozyu</th>\n",
       "      <th>zytkow</th>\n",
       "      <th>zz214</th>\n",
       "      <th>zzlsa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60925 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  00001  00003000140  00003003958  00007  0001  00010  00014  \\\n",
       "0   0    0     0      0            0            0      0     0      0      0   \n",
       "1   0    0     0      0            0            0      0     0      0      0   \n",
       "2   0    0     0      0            0            0      0     0      0      0   \n",
       "3   1    1     0      0            0            0      0     0      0      0   \n",
       "4   0    0     0      0            0            0      0     0      0      0   \n",
       "\n",
       "   ...  zwischen  zwitserlood  zxgah7qabjh  zybatov  zybatow  zygmunt  \\\n",
       "0  ...         0            0            0        0        0        0   \n",
       "1  ...         0            0            0        0        0        0   \n",
       "2  ...         0            0            0        0        0        0   \n",
       "3  ...         0            0            0        0        0        0   \n",
       "4  ...         0            0            0        0        0        0   \n",
       "\n",
       "   zyokyoozyu  zytkow  zz214  zzlsa  \n",
       "0           0       0      0      0  \n",
       "1           0       0      0      0  \n",
       "2           0       0      0      0  \n",
       "3           0       0      0      0  \n",
       "4           0       0      0      0  \n",
       "\n",
       "[5 rows x 60925 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the vectorizer \n",
    "vectorizer = CountVectorizer(binary = True)\n",
    "\n",
    "# Create the DTM\n",
    "X = vectorizer.fit_transform(email.message).toarray() # Learn vocabulary and return DTM\n",
    "vocabulary = vectorizer.get_feature_names_out()       # Get output feature names for transformation\n",
    "X = pd.DataFrame(X, columns = vocabulary)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75eb50c6-379d-4bae-9fd8-6226298aee43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1645257973526,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "75eb50c6-379d-4bae-9fd8-6226298aee43",
    "outputId": "bb36b903-ce32-44f3-dac5-318e4296f6ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "Name: spam, dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the output y as spam indicators\n",
    "y = email[\"spam\"] == True\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c453ec4-d8db-4efa-8552-ead85a485e9c",
   "metadata": {
    "id": "5c453ec4-d8db-4efa-8552-ead85a485e9c"
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352cf962-8299-4ae6-ac74-ea4535884580",
   "metadata": {
    "id": "352cf962-8299-4ae6-ac74-ea4535884580"
   },
   "source": [
    "How many different documents (emails) and different tokens (words) do you have in this data?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a2fbdbe-6350-4310-8f11-bc8dc9083919",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1645257973527,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "6a2fbdbe-6350-4310-8f11-bc8dc9083919",
    "outputId": "2c95c7ab-3956-4a48-f20c-5d259cd1a89d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2893"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Report the number of emails\n",
    "email.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "223cb0d2-ce1d-4f04-a4d7-797101f02e30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645257973527,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "223cb0d2-ce1d-4f04-a4d7-797101f02e30",
    "outputId": "36bf0723-09bf-4c4a-99e1-1f37604a3c9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60925"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Report the number of words\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c1c99a-4659-414e-b5ef-86f00c3d1078",
   "metadata": {
    "id": "a5c1c99a-4659-414e-b5ef-86f00c3d1078"
   },
   "source": [
    "_There are **2893 documents** and **60925 tokens** in this data._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d51ce07-d0cc-4899-b194-c484c4cd3242",
   "metadata": {
    "id": "8d51ce07-d0cc-4899-b194-c484c4cd3242"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5bd96a-93f5-4e75-9d0b-2f2e23197386",
   "metadata": {
    "id": "1c5bd96a-93f5-4e75-9d0b-2f2e23197386"
   },
   "source": [
    "3\\. (2pt) Split data into training/validation chunks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae670c24-14fb-4ade-b4c3-d07399c1af5d",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1645257973527,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "ae670c24-14fb-4ade-b4c3-d07399c1af5d"
   },
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f68fe1a9-74ca-4ec1-9a7d-1792d7bb81f4",
   "metadata": {
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1645257974146,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "f68fe1a9-74ca-4ec1-9a7d-1792d7bb81f4"
   },
   "outputs": [],
   "source": [
    "# Split DTM and email data into random training and validation subsets\n",
    "Xt, Xv, yt, yv = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb642597-2512-4ada-b05a-364bd7f0a6a6",
   "metadata": {
    "id": "eb642597-2512-4ada-b05a-364bd7f0a6a6"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84867af-c8e8-4af0-9cff-4790b77a8bfe",
   "metadata": {
    "id": "a84867af-c8e8-4af0-9cff-4790b77a8bfe"
   },
   "source": [
    "4\\. (2pt) Design a scheme to name your variables so you can understand from the variable name which mathematical concept it refers to. You need variables like  \n",
    "- $Pr(S = 1)$: probability of spam  \n",
    "- $Pr(S = 0|W = 1)$: probability the email is not spam given it cointains the word W  \n",
    "- $log Pr(W = 1)$: log probability of word present  \n",
    "\n",
    "Explain how would you name these examples.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d43248-cb23-4443-83c9-7bd0afd765a1",
   "metadata": {
    "id": "07d43248-cb23-4443-83c9-7bd0afd765a1"
   },
   "source": [
    "_The variable names will follow the scheme as displayed below:_ \n",
    "    \n",
    "| Variable Name | Notation                 | Definition                                                          |\n",
    "|---------------|--------------------------|--------------------------------------------------------------------|\n",
    "| Pr_S1         | $$Pr(S = 1)$$            | Probability that the email is spam                               |\n",
    "| Pr_S0         | $$Pr(S = 0)$$            | Probability that the email is non-spam                           |\n",
    "| Pr_W1_S1      | $$Pr(W = 1\\|S = 1)$$     | Conditional probability that the word is present in spam emails     |\n",
    "| Pr_W1_S0      | $$Pr(W = 1\\|S = 0)$$     | Conditional probability that the word is present in non-spam emails |\n",
    "| logPr_S1      | $$log Pr(S = 1)$$        | Log probability that the email is spam                            |\n",
    "| logPr_S0      | $$log Pr(S = 0)$$        | Log probability that the email is non-spam                        |\n",
    "| logPr_W1_S1   | $$log Pr(W = 1\\|S = 1)$$ | Log probability that the word is present in spam emails             |\n",
    "| logPr_W1_S0   | $$log Pr(W = 1\\|S = 0)$$ | Log probability that the word is present in non-spam emails         |\n",
    "| L_S1          | $$\\ell(S = 1\\|W)$$       | Log-likelihood for spam                                            |\n",
    "| L_S0          | $$\\ell(S = 0\\|W)$$       | Log-likelihood for non-spam                                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdd1256-f52d-4356-8d9e-8ce138247834",
   "metadata": {
    "id": "afdd1256-f52d-4356-8d9e-8ce138247834"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c84e874-7c85-4ee6-899c-58132aa5ecb8",
   "metadata": {
    "id": "2c84e874-7c85-4ee6-899c-58132aa5ecb8"
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1401fb27-6de2-47d5-9cd3-d820382d878f",
   "metadata": {
    "id": "1401fb27-6de2-47d5-9cd3-d820382d878f"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc87b29-5b7d-486b-941f-34aa2e32c411",
   "metadata": {
    "id": "6fc87b29-5b7d-486b-941f-34aa2e32c411"
   },
   "source": [
    "# 2 Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e52c2-cd7d-47f8-843e-36ce7685d66f",
   "metadata": {
    "id": "3f4e52c2-cd7d-47f8-843e-36ce7685d66f"
   },
   "source": [
    "Before you get into the business, here are two warming-up exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac67e5d-22f8-49b6-91ed-6412dd45eebc",
   "metadata": {
    "id": "7ac67e5d-22f8-49b6-91ed-6412dd45eebc"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6d3de5-4cc9-48e8-ae39-05f65487a6d6",
   "metadata": {
    "id": "6c6d3de5-4cc9-48e8-ae39-05f65487a6d6"
   },
   "source": [
    "1\\. (4pt) Here is a small excerpt from the initial DTM (before you split it into training/validation), corresponding to rows 946 to 948, and to columns 30,037..30,042:  \n",
    "  \n",
    "`  X[946:949, 30037:30042].toarray()`  \n",
    "`  array([[0, 0, 0, 0, 0],`  \n",
    "`         [0, 0, 1, 0, 0],`  \n",
    "`         [0, 0, 0, 0, 0]])`  \n",
    "  \n",
    "What do these numbers show:   \n",
    "Note: you should have the same numbers in your analysis, this is not random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4847261-4125-4f67-af83-b8e026dce2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the excerpt from DTM\n",
    "X.iloc[946:949, 30037:30042].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb720fa-3c12-4743-aaa3-db10885499d3",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1feaa8-3a27-48e3-b4b7-2766a2c27107",
   "metadata": {
    "id": "5b1feaa8-3a27-48e3-b4b7-2766a2c27107"
   },
   "source": [
    "(a) which emails do the rows correspond to?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a539577-1c04-4dc8-bebe-13786e7db007",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1645257974147,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "6a539577-1c04-4dc8-bebe-13786e7db007"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "946    Subject: efl position in israel  i have been a...\n",
       "947    Subject: job : english in keio univ ( 2nd post...\n",
       "948    Subject: icslp 96  = = = = = = = = = = = = = =...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the corresponding emails\n",
    "email.message[946:949]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d8746c-ed6a-4784-aa77-75b32b11aac6",
   "metadata": {},
   "source": [
    "_The rows corresponds to **the emails at indices 946 to 948**, as shown above._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f649f441-87b6-446e-8fb2-b477040f7aa7",
   "metadata": {
    "id": "f649f441-87b6-446e-8fb2-b477040f7aa7"
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fc0c70-1375-4853-adc3-350b8b7c09e4",
   "metadata": {
    "id": "56fc0c70-1375-4853-adc3-350b8b7c09e4"
   },
   "source": [
    "(b) Which words do the columns correspond to?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d18894d-24d5-4afd-a8d2-09de1f3a497d",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1645257974148,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "6d18894d-24d5-4afd-a8d2-09de1f3a497d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['interventions', 'intervient', 'interview', 'interviewed',\n",
       "       'interviewing'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the corresponding words\n",
    "X.columns[30037:30042]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be170d8-884a-4b0d-a059-9e84ea957ed5",
   "metadata": {},
   "source": [
    "_The columns correspond to the words **\"interventions\", \"intervient\", \"interview\", \"interviewed\", \"interviewing\"**._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6240e345-9aba-45d6-b47e-c8ed23db289a",
   "metadata": {
    "id": "6240e345-9aba-45d6-b47e-c8ed23db289a"
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca7e85e-8bcd-42c2-a8a9-c935b6ecad2b",
   "metadata": {
    "id": "4ca7e85e-8bcd-42c2-a8a9-c935b6ecad2b"
   },
   "source": [
    "(c) What does the single “1” in the middle of the table mean?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71645d13-bca3-4f54-85ee-5efcc8905582",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1645257974148,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "9fc31c77-da67-4da9-9be0-3493da9accd9"
   },
   "source": [
    "_Since we are using the binary count vectorizer, the \"1\" in the middle indicates that **the presence of word \"interview\" in the email at row index 947**._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeeaeea-620f-4a95-b5d1-1fba84d5df7e",
   "metadata": {
    "id": "edeeaeea-620f-4a95-b5d1-1fba84d5df7e"
   },
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc931ad-7998-4320-bd61-9df7b7d8f472",
   "metadata": {
    "id": "9cc931ad-7998-4320-bd61-9df7b7d8f472"
   },
   "source": [
    "(d) What do the zeros mean?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1929c8f1-8aa0-47b2-a616-b895d1d9e3ac",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1645257974149,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "89658845-737d-4ccc-9de8-e6c8e0874488"
   },
   "source": [
    "_The zeros mean that **the corresponding word does not appear in the corresponding email**._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb57c8b-bcb3-4993-aff9-743bd8f63d9c",
   "metadata": {
    "id": "5bb57c8b-bcb3-4993-aff9-743bd8f63d9c"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5326b2-fa4e-443f-b469-598722498621",
   "metadata": {
    "id": "de5326b2-fa4e-443f-b469-598722498621"
   },
   "source": [
    "2\\. (2pt) What is the accuracy of the naive model that predicts all emails into the majority category?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12506199-21ec-4c4a-8ee4-ad50e019edaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the majority category\n",
    "y.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3a9968c-5e7a-4267-9341-db4d6210ad0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict all emails into the majority category\n",
    "yhat = np.zeros(y.size)\n",
    "yhat[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1151918f-2498-4ff0-bf54-059aeda2cf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8337366055997235"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the accuracy of this naive model\n",
    "np.mean(y == yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b85a65-f632-4164-8c5b-cea74f80bf3f",
   "metadata": {},
   "source": [
    "_The accuracy of the naive model that predicts all emails into the majority category (which is non-spam) is **83.37%**._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee93d67-9af7-4267-aaf3-d5d9e3ca31a3",
   "metadata": {
    "id": "3ee93d67-9af7-4267-aaf3-d5d9e3ca31a3"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b20bdd8-f2b8-4b74-8437-9daf17ffc88b",
   "metadata": {
    "id": "2b20bdd8-f2b8-4b74-8437-9daf17ffc88b"
   },
   "source": [
    "Now the data is in shape and it is time to get serious. But first things first. Ensure you are familiar with Naive Bayes. Consult the readings, available on canvas.\n",
    "- Lecture notes Section 7.3 is written with this task in mind.   \n",
    "- Schutt & O’Neill is an easy and accessible (and long) introduction,  \n",
    "- Whitten & Frank is a lot shorter but still accessible introduction.  \n",
    "\n",
    "Good. Now you are ready with the preparatory work and it’s time to dive into the real thing. Let’s implement Naive Bayes. Use only training data in the fitting below. We also do it in a slightly simpler way and ignore the missing words when computing the probabilites, i.e. we only look for the effect of a word’s presence, not for the effect of its absence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01803803-b1fd-44b3-a4f0-9aada83ddb60",
   "metadata": {
    "id": "01803803-b1fd-44b3-a4f0-9aada83ddb60"
   },
   "source": [
    "3\\. (3pt) Compute the unconditional (log) probability that the email is spam/non-spam, $log Pr(S = 1)$, and $log Pr(S = 0)$. These probabilities are based on the values of $y$ (i.e. spam) alone. They do not contain information about the words in emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e3ff48c-45aa-452c-b12e-fea33d40654a",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1645257974149,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "0e3ff48c-45aa-452c-b12e-fea33d40654a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.798697918572976, 2.7986979185729757)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the log probabilities for spam/non-spam\n",
    "logPr_S1 = np.log(np.mean(yt))\n",
    "logPr_S0 = 1 - logPr_S1\n",
    "logPr_S1, logPr_S0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9422c24a-ef93-40c9-8bad-2d6ee22c328d",
   "metadata": {
    "id": "9422c24a-ef93-40c9-8bad-2d6ee22c328d"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba22a65a-1efe-452b-8300-cd8b62300ed5",
   "metadata": {
    "id": "ba22a65a-1efe-452b-8300-cd8b62300ed5"
   },
   "source": [
    "4\\. (8pt) For each word $w$, compute the (log) probability that the word is present in spam emails, $log Pr(W = 1|S = 1)$, and (log) probability that the word is present in non-spam emails, $log Pr(W = 1|S = 0)$. These probabilities can easily be calculated from counts of how many times these words are present for each class.  \n",
    "Hint: these computations are based on your BOW-s $X$. Look at ways to sum along columns in this matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "054c638c-fdcd-47f5-b128-6e559a634963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2163/1974588754.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  logPr_W1_S1 = np.array([np.log(np.mean(Xt[w][yt == 1])) for w in Xt.columns])\n",
      "/tmp/ipykernel_2163/1974588754.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  logPr_W1_S0 = np.array([np.log(np.mean(Xt[w][yt == 0])) for w in Xt.columns])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-1.11175308, -1.1689115 , -5.94803499, -5.94803499,        -inf]),\n",
       " array([-1.7819681 , -3.00144509, -7.56579328,        -inf, -6.8726461 ]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the log probabilities for presence of word in spam/non-spam\n",
    "logPr_W1_S1 = np.array([np.log(np.mean(Xt[w][yt == 1])) for w in Xt.columns])\n",
    "logPr_W1_S0 = np.array([np.log(np.mean(Xt[w][yt == 0])) for w in Xt.columns])\n",
    "logPr_W1_S1[:5], logPr_W1_S0[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d161442-cda1-4351-8280-8f5e7999b390",
   "metadata": {
    "id": "0d161442-cda1-4351-8280-8f5e7999b390"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30f2f4d-928c-4185-b09c-c02647b997e0",
   "metadata": {
    "id": "e30f2f4d-928c-4185-b09c-c02647b997e0"
   },
   "source": [
    "Now we are done with the estimator. Your fitted model is completely described by these four probability vectors: $log Pr(S = 1)$, $log Pr(S = 1)$, $log Pr(W = 1|S = 1)$, $log Pr(W = 1|S = 0)$. Let’s now pull out your validation data and do some predictions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc378e41-c0d3-494c-b150-338b982353a9",
   "metadata": {
    "id": "bc378e41-c0d3-494c-b150-338b982353a9"
   },
   "source": [
    "5\\. (10pt) For both classes, $S = 1$ and $S = 0$, compute the log-likelihood that the email belongs to this class. Log-likelihood is given as (7.3.13, page 260 for now) in lecture notes, and the equations on Schutt “Doing Data Science”, page 102.  \n",
    "Computing the likelihoods involves sums of the previously computed probabilities, $log Pr(W = 1|S)$, and BOW elements $x_{ij}$. Start by doing this by whatever way you can get it done (e.g. loops). The most important thing is that you understand what you do!  \n",
    "But if you want to write efficient code, use matrix product instead (it is ∼ 1000× faster than loops). You can also check out np.apply_along_axis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018bc268-5e9b-47ca-81a2-e758695dcb0f",
   "metadata": {},
   "source": [
    "_The log-likelihoods can be computed using:_  \n",
    "<em>$$\\ell(S = 1|W) = log Pr(S = 1) + \\sum^{K}_{j = 1} log Pr(W_j = 1|S = 1) \\cdot \\mathbb{1}(W_j = 1)$$</em>\n",
    "<em>$$\\ell(S = 0|W) = log Pr(S = 0) + \\sum^{K}_{j = 1} log Pr(W_j = 1|S = 0) \\cdot \\mathbb{1}(W_j = 1)$$</em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "522b3d7d-13fb-44d0-95e9-c287a68bc1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2163/572226100.py:2: RuntimeWarning: invalid value encountered in matmul\n",
      "  L_S1 = logPr_S1 + Xv.values @ logPr_W1_S1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the log-likelihood for spam\n",
    "L_S1 = logPr_S1 + Xv.values @ logPr_W1_S1\n",
    "L_S1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f1a0311-d703-4812-aa97-8dc4098ccfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2163/3955572254.py:2: RuntimeWarning: invalid value encountered in matmul\n",
      "  L_S0 = logPr_S0 + Xv.values @ logPr_W1_S0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the log-likelihood for non-spam\n",
    "L_S0 = logPr_S0 + Xv.values @ logPr_W1_S0\n",
    "L_S0[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e40ec9d-5f09-49a8-b91c-1aeb5bee600a",
   "metadata": {
    "id": "4e40ec9d-5f09-49a8-b91c-1aeb5bee600a"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87ae2f3-e0d4-4d46-95d6-11f38815f026",
   "metadata": {
    "id": "d87ae2f3-e0d4-4d46-95d6-11f38815f026"
   },
   "source": [
    "6\\. (2pt) How many log-likelihoods you have to compute? Explain why do you have to have this many log-likelihoods.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d8bdc0d-74e7-41e9-93bd-0a058482898b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1158"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_S1.shape[0] + L_S0.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31658a27-74c0-4bb1-aab0-7576ca44bb92",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1645257974150,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "747825b9-2279-478c-a8d2-bbd11e6553b0"
   },
   "source": [
    "_We have to compute a total of **1158 log-likelihoods**, with 579 emails in our validation data and 2 log-likelihoods for each email to make predictions._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6db64e-536c-4e87-b3c3-038e7744298f",
   "metadata": {
    "id": "3f6db64e-536c-4e87-b3c3-038e7744298f"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00252031-7846-4385-942c-c6e8ca862225",
   "metadata": {
    "id": "00252031-7846-4385-942c-c6e8ca862225"
   },
   "source": [
    "7\\. (7pt) Based on the log-likelihoods, predict the class $S = 1$ or $S = 0$ for each email in the validation set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d95552b-7894-4e8a-be31-940e8e73ef4c",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1645257974151,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "7d95552b-7894-4e8a-be31-940e8e73ef4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict whether the email is spam based on log-likelihoods\n",
    "yhat = L_S1 > L_S0\n",
    "yhat[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af48298d-7b82-430c-ba20-de30d24301fa",
   "metadata": {
    "id": "af48298d-7b82-430c-ba20-de30d24301fa"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ccdc9d-6544-4beb-915f-da02dc089ca4",
   "metadata": {
    "id": "f4ccdc9d-6544-4beb-915f-da02dc089ca4"
   },
   "source": [
    "8\\. (3pt) Print the resulting confusion matrix and accuracy (feel free to use existing libraries).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20e32e21-673e-4d14-ac52-e4d5f373d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c749f98-f147-4b92-a554-a5cd599038de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[481,   0],\n",
       "       [ 98,   0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "confusion_matrix(yv, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1054743-c791-4de3-b225-122c47270af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8307426597582038"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the accuracy\n",
    "accuracy_score(yv, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92b556b-6c58-4d7b-9abd-d10bfef52169",
   "metadata": {
    "id": "d92b556b-6c58-4d7b-9abd-d10bfef52169"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b171e1-3f6b-4237-bd8a-f67e82a09216",
   "metadata": {
    "id": "31b171e1-3f6b-4237-bd8a-f67e82a09216"
   },
   "source": [
    "9\\. (5pt) If your results are like mine, you can see that the results are not impressive at all, your model works no better than the naive guess. Explain why do you get such mediocre results.  \n",
    "Note: just explain, but do not do anything about it! We’ll attack the problem in the next question with smoothing.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca102d-e254-4cad-85e7-e643bdcecf3d",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1645257974400,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "34b22a88-0613-4786-9ebe-245f335a9f18"
   },
   "source": [
    "_With missing words in our training sample, the log conditional probabilities may result in $log Pr(W = 1|S) = log(0) = -\\infty$; this corrupts the model as we further multiply these log-probabilities with the indicators, which leads to \"nan\" in the resulting log-likelihoods. Then, if we further investigate the predictions yhat, we will see that the model categorizes every single email as non-spam as it fails to compare two \"nan-s\". So essentially it's performing the same task as the naive model that predicts all emails into the majority category in Question 2.2 - and in this sense, the accuracy doesn't really improve._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f00fa6d-031c-48b3-af4a-38921e0a6551",
   "metadata": {
    "id": "1f00fa6d-031c-48b3-af4a-38921e0a6551"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5150916-c555-4064-a1f9-8451509e1f45",
   "metadata": {
    "id": "d5150916-c555-4064-a1f9-8451509e1f45"
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7309eb2f-791f-490a-8798-3a9be657d652",
   "metadata": {
    "id": "7309eb2f-791f-490a-8798-3a9be657d652"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b73bc2-f52a-4bff-b7a6-3d039fd59589",
   "metadata": {
    "id": "66b73bc2-f52a-4bff-b7a6-3d039fd59589"
   },
   "source": [
    "# 3 Add Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ec3f0-3ee2-47bf-b22e-152236edbe9a",
   "metadata": {
    "id": "3d4ec3f0-3ee2-47bf-b22e-152236edbe9a"
   },
   "source": [
    "So, now you have your brand-new NB algorithm up and running. But the results are not impressive... As a next step, we add smoothing to the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4185c2-043a-4fe5-9cc0-43c6a566af49",
   "metadata": {
    "id": "3c4185c2-043a-4fe5-9cc0-43c6a566af49"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d18eb-8f26-447d-8b3f-07f26108b92d",
   "metadata": {
    "id": "999d18eb-8f26-447d-8b3f-07f26108b92d"
   },
   "source": [
    "1\\. (2pt) As you will be doing validation below, your first task is to mold what you did above into two funcions: one for fitting and another one for predicting. You can mostly copy-paste your code from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce2234-b886-4dd7-a473-2aee4c781b09",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1645257974400,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "d5ce2234-b886-4dd7-a473-2aee4c781b09"
   },
   "outputs": [],
   "source": [
    "###### 正在施工中 ######\n",
    "\n",
    "def fit(Xt, yt):\n",
    "    # Compute the log probabilities for spam/non-spam\n",
    "    logPr_S1 = np.log(np.mean(yt))\n",
    "    logPr_S0 = 1 - logPr_S1\n",
    "    logPr_S1, logPr_S0\n",
    "    # Compute the log probabilities for presence of word in spam/non-spam\n",
    "    logPr_W1_S1 = np.array([np.log(np.mean(Xt[w][yt == 1])) for w in Xt.columns])\n",
    "    logPr_W1_S0 = np.array([np.log(np.mean(Xt[w][yt == 0])) for w in Xt.columns])\n",
    "    logPr_W1_S1[:5], logPr_W1_S0[:5]\n",
    "    \n",
    "    \n",
    "def predict(Xv, yv):\n",
    "    # Compute the log-likelihood for spam\n",
    "    L_S1 = logPr_S1 + Xv.values @ logPr_W1_S1\n",
    "    L_S1[:5]\n",
    "    # Compute the log-likelihood for non-spam\n",
    "    L_S0 = logPr_S0 + Xv.values @ logPr_W1_S0\n",
    "    L_S0[:5]\n",
    "    # Predict whether the email is spam based on log-likelihoods\n",
    "    yhat = L_S1 > L_S0\n",
    "    yhat[:5]\n",
    "    # Compute the accuracy\n",
    "    accuracy_score(yv, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4596e9-3e00-4d61-b9aa-c01b4c86de00",
   "metadata": {
    "id": "bb4596e9-3e00-4d61-b9aa-c01b4c86de00"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6836e4-3755-4f6b-af1b-281b7fd156de",
   "metadata": {
    "id": "fd6836e4-3755-4f6b-af1b-281b7fd156de"
   },
   "source": [
    "2\\. (18pt) Add smoothing to the model. Smoothing amounts to assuming that we have “seen” every possible word $\\alpha \\geq 0$ times already, in both spam and non-spam emails. Note that $\\alpha$ does not have to be an integer, and typically the best $\\alpha < 1$.  \n",
    "What you have to do is to re-compute the probabilities $log Pr(S)$, $log Pr(\\bar{S})$, $log Pr(w|S)$, $log Pr(w|\\bar{S})$, the predictions part will remain unchanged. So you should update your fitting function by adding an additional argument α to it, and modify the probabilities accordingly.\n",
    "See Lecture notes, the subsection for smoothing; and Schutt p 103 and p 109 for more explanations.    \n",
    "Note: it is advantageous to make your model as two functions: one for fitting, and another for prediction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad8951f-fb1f-44d1-afc8-d5d935aa64e3",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1645257974401,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "aad8951f-fb1f-44d1-afc8-d5d935aa64e3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e47d7cbe-7f44-4105-a85c-e2971530b851",
   "metadata": {
    "id": "e47d7cbe-7f44-4105-a85c-e2971530b851"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7843e6d-f71a-4f41-8129-ebabb84c1a29",
   "metadata": {
    "id": "c7843e6d-f71a-4f41-8129-ebabb84c1a29"
   },
   "source": [
    "3\\. (5pt) Use your updated model for predictions with a few different $\\alpha$-values and report the corresponding confusion matrix and accuracy.  \n",
    "A well-implemented algorith should not spend more than a few seconds on both fitting and predicting. However, more important that you understand what you are doing!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a54f783-fe98-4458-b612-00c54a78f0c4",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1645257974401,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "5a54f783-fe98-4458-b612-00c54a78f0c4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f949e752-6d56-4ed5-82be-197c656b4bd9",
   "metadata": {
    "id": "f949e752-6d56-4ed5-82be-197c656b4bd9"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716d06a7-55a3-4cb4-a63b-83f6ebc1f9b7",
   "metadata": {
    "id": "716d06a7-55a3-4cb4-a63b-83f6ebc1f9b7"
   },
   "source": [
    "4\\. (5pt) Find the best smoothing parameter $\\alpha$.   \n",
    "You can just run a loop over different values, but start with very small values ($10^{−8}$, $10^{−7}$ and such). Check out np.logspace about how to do such sequences. Use the largest $\\alpha = 10$ or so.  \n",
    "Note: this is fairly fast if your algorithm is fast. But even if your algorithm is slow, still do your best!  \n",
    "If your results are like mine, your best accuracy will be > 99.5%. (But this result is random!)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b8d89f-164e-4816-83df-d6d9625bebb1",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1645257974401,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "67b8d89f-164e-4816-83df-d6d9625bebb1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d41662e7-4722-4af5-b427-74381414f94a",
   "metadata": {
    "id": "d41662e7-4722-4af5-b427-74381414f94a"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c7731d-0bcb-4150-bac4-7ab4e17049e8",
   "metadata": {
    "id": "66c7731d-0bcb-4150-bac4-7ab4e17049e8"
   },
   "source": [
    "5\\. (2pt) Plot how accuracy depends on $\\alpha$. Use log-scale for $\\alpha$!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a027705-ddbd-4f9f-9be9-50bbff34bd97",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1645257974401,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "6a027705-ddbd-4f9f-9be9-50bbff34bd97"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8773d97c-e261-4612-b725-79f8d7d05256",
   "metadata": {
    "id": "8773d97c-e261-4612-b725-79f8d7d05256"
   },
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598ed202-f5ae-4495-8031-f42df37921d1",
   "metadata": {
    "id": "598ed202-f5ae-4495-8031-f42df37921d1"
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd160a18-19f2-4530-af52-b93aa1e2305b",
   "metadata": {
    "id": "bd160a18-19f2-4530-af52-b93aa1e2305b"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ac7df9-0c1d-4355-aea2-476c5a5bac18",
   "metadata": {
    "id": "59ac7df9-0c1d-4355-aea2-476c5a5bac18"
   },
   "source": [
    "# 4 Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ae7dc4-aeaf-4b48-9725-42ec27a33675",
   "metadata": {
    "id": "26ae7dc4-aeaf-4b48-9725-42ec27a33675"
   },
   "source": [
    "Naive Bayes is interpretable – in a little similar fashion like linear regression. But in only a little similar fashion. Namely, we can find the words that are the best predictors that an email is spam, and the best predictors that email is non-spam. And we want to look at reasonably common words only, say more frequent than 10 times in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b415ce02-5d8d-4861-bcca-82c177d90635",
   "metadata": {
    "id": "b415ce02-5d8d-4861-bcca-82c177d90635"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76c9ea8-52eb-4ffe-9c72-c16b79a47dc8",
   "metadata": {
    "id": "c76c9ea8-52eb-4ffe-9c72-c16b79a47dc8"
   },
   "source": [
    "1\\. (10pt) Which words are the best predictors that an email is spam? These are the word where $Pr(S = 1|W = 1)$ is large and $Pr(S = 0|W = 1)$ is small, or to put it differently, where $log Pr(S = 1|W = 1) − log Pr(S = 0|W = 1)$ is large.  \n",
    "Explain why this is the case.  \n",
    "Hint: you may re-check the concept of log-likelihood and how that is used for prediction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa18b593-30f5-4d37-a2f3-03df1ba9e085",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1645257974402,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "aa18b593-30f5-4d37-a2f3-03df1ba9e085"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43609097-5aed-4bb6-b603-4b6c088011fb",
   "metadata": {
    "id": "43609097-5aed-4bb6-b603-4b6c088011fb"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b23774-ccd4-466a-af2a-b6c3ae10a01d",
   "metadata": {
    "id": "22b23774-ccd4-466a-af2a-b6c3ae10a01d"
   },
   "source": [
    "2\\. (10pt) Find 10 best words to predict spam and 10 best words to predict non-spam. Comment your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3272c2-8d81-4498-96bf-14773b8421da",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1645257974402,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "2e3272c2-8d81-4498-96bf-14773b8421da"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "326dc583-7e6a-4c31-8c7a-775fb7da2214",
   "metadata": {
    "id": "326dc583-7e6a-4c31-8c7a-775fb7da2214"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cb32e5-03a8-4277-b83f-be057fa976fa",
   "metadata": {
    "id": "e4cb32e5-03a8-4277-b83f-be057fa976fa"
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b298747e-4db5-4e66-8a13-a1141bf1071c",
   "metadata": {
    "id": "b298747e-4db5-4e66-8a13-a1141bf1071c"
   },
   "source": [
    "How many hours did you spend on this PS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee8b1dd-13da-4d21-8541-6a5b0a67e149",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1645257974402,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "caed9399-b741-436f-a886-abbea0b37e94"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e333810d-3d47-4a7c-8e11-652b258f9b21",
   "metadata": {
    "id": "e333810d-3d47-4a7c-8e11-652b258f9b21"
   },
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60a91eb-4c0b-4efa-9ec4-b633b042d6ff",
   "metadata": {
    "id": "d60a91eb-4c0b-4efa-9ec4-b633b042d6ff"
   },
   "source": [
    "# 5 Extra Credit: Implement Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5d9962-18a4-46bf-939a-334fb0ccc1eb",
   "metadata": {
    "id": "3b5d9962-18a4-46bf-939a-334fb0ccc1eb"
   },
   "source": [
    "Above we just did validation using testing/validation set approach. But cross-validation is better–it avoids much of the random noise when doing the split. Here your task is to implement CV yourself without using existing libraries!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf3b967-e594-48d9-bc70-29af8d22397a",
   "metadata": {
    "id": "dcf3b967-e594-48d9-bc70-29af8d22397a"
   },
   "source": [
    "- Implement $k$-fold CV. I recommend to implement it as a function that a) puts your data into random order; b) splits these into $k$ chunks; c) selects a chunk for testing and the others for training; d) trains your NB model on the training chunks; e) computes accuracy on training chunk; f) returns mean accuracy over all these $k$ trials. The function should also take $\\alpha$ as an argument, this is the hyperparameter you are going to optimize.  \n",
    "-  Find the optimal $\\alpha$ by 5-fold CV using your own CV code. You have to find the cross-validated accuracies for a number of $\\alpha$-s between 0 and 1. Present the accuracy as a function of $\\alpha$ on a plot and indicate which one is the best $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9801338-4c02-4c49-89c4-091d4e4ecce6",
   "metadata": {
    "id": "758e5b04-65b5-4b6b-bc58-16593fb5cb16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'numpy     : 1.20.3\\npandas    : 1.3.4\\nmatplotlib: 3.4.3\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "import watermark.watermark as watermark\n",
    "\n",
    "\n",
    "watermark(iversions=True, globals_=globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbdbabd8-049f-47e2-86f7-e4fdb7a6b43a",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1645257974402,
     "user": {
      "displayName": "Qing Nie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gga_c2JFFuGErDIL0CfdYIGlWjOT62OvrWQYdlA=s64",
      "userId": "13584123132994024280"
     },
     "user_tz": 480
    },
    "id": "cbdbabd8-049f-47e2-86f7-e4fdb7a6b43a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: pandas\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf55878d-6516-43a9-aa80-fb6bc0ba724a",
   "metadata": {},
   "outputs": [],
   "source": [
    " %reload_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae31b819-dc60-45c7-8a12-b42652e3fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e09b2c1-4feb-490f-af42-9812751e760c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.9.7\n",
      "IPython version      : 7.29.0\n",
      "\n",
      "np : not installed\n",
      "pd : not installed\n",
      "plt: not installed\n",
      "\n",
      "Compiler    : GCC 9.4.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.144+\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 4\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p np,pd,plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd980b50-8693-49f0-9a47-e94271b79113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6fc87b29-5b7d-486b-941f-34aa2e32c411",
    "66b73bc2-f52a-4bff-b7a6-3d039fd59589",
    "59ac7df9-0c1d-4355-aea2-476c5a5bac18",
    "d60a91eb-4c0b-4efa-9ec4-b633b042d6ff"
   ],
   "name": "ps06-naive-bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
